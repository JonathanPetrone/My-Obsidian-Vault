Building - "the process of creating or developing something"
Adaptive - "having an ability to change to suit changing conditions"
Expertise - "a high level of knowledge or skill"

Adaptive + Expertise = The ability to attain a high level of knowledge or skill in changing conditions

## Expertise Building through Curiosity
Being adaptive means being curious about the new conditions. Curiosity builds with a balance in three areas [[Knowledge, Surprise, Confidence's relation to Curiosity|Knowledge, Surprise, Confidence]], too much or too little stifles curiosity.  The drive to turn information into knowledge (Epistemic curiosity) is a strong contributor in building expertise in any domain.

Knowledge accumulation is exponential if you combine it with curiosity and exploration. [[Current Mental Models & Frameworks#The Matthew Principle|The Matthew Principle]] is true here, the more knowledge you have the more you can easily build. To build more skill and knowledge at the same time the concept of [[Be a Thinkerer|Thinkering]] can be useful as it encourages running experiments against what you know. 

WHY and HOW questions are important for curiosity and expertise building as they encourage exploration and experiments, and also often results in generating new questions which leads to more exploration and so on. In contrast WHAT questions tend to be more close-ended and definitive.

## Tools For Building Adaptive Expertise 
Powerful tools for building expertise are [[Thinking Structures as Tools for Learning|Thinking Structures]] because they helps us with something to hold onto while thinking, learning, acting, and remembering. There are different structures that are effective depending on the job, some are for recall or remembering, some can be used to cultivate exploration and thinking. Examples are heuristics, mnemonics, models, and mind maps etc.

Building a [[Second Brain]] is a way to store store information from diverse sources (text, video, conversations), that might help you synthesize insights across different domains. Using this [[Second Brain]] as a tool to express, synthesize and cultivate knowledge is a way to keep what resonates with you to let it influence the future you and [[Self-expression through writing is a fundamental self-learning tool|Solidifying what you learn.]]  The [[The Process of Information Gathering Effectively|CODE model]] is a useful framework for the process of information gathering. 

## Analyze the Environment for Rapid Expertise Building
The right approach for building expertise depends on the nature of the environment, is the domain/area/problem [[Complicated and Complex Expertise|Complicated or Complex]]? Complicated domains tend to benefit most from deliberate practice, simplest complete system training and drills. Complex domains tend to benefit from varied context exposure, abstract patterns across instances, first principles. 

There is also the dimension of feedback loops, are they fast or slow? This leads us to a model of different domain spaces and their characteristics:

![[Adaptive expertise (4).jpg|300]]

%% Connect the model to concrete tips%%


___

%%
[[The Limited Supply of Attention]]- > Focus on what matters
%%


Transfer of Learning wiki:
- Transfer of learning [Transfer of Learning](https://en.wikipedia.org/wiki/Transfer_of_Learning "Transfer of Learning") Can I see if anything relating on how to best transfer skill/learning/knowledge
	- **Core mechanisms:**
	
	- **Abstraction** - Deliberately extracting underlying principles, creating models, finding analogies/metaphors. This builds associations that enable transfer beyond surface similarities.
	- **Varied practice contexts** - Learning in multiple contexts creates more retrieval paths and encourages generalization rather than context-locked knowledge.
	
	**Teaching strategies (Perkins & Salomon):**
	
	_Hugging_ - Make learning environment similar to application context. Methods: simulation games, mental practice, contingency learning. (Basically: practice in realistic conditions)
	
	_Bridging_ - Explicitly connect learning to other domains. Methods: brainstorming connections, developing analogies, metacognitive reflection. (Basically: force pattern extraction)

- https://en.wikipedia.org/wiki/Dreyfus_model_of_skill_acquisition  Five Stages of Skill Acquisition -> Can i use this model to reason about interventions at different stages???

[[Principles of Ultralearning]] - Scott H. Young
[[Buccaneer-Scholar Self-Education Method]] - James Bach

### Anders Ericsson
**Core:** Deliberate practice ≠ experience. Requires: specific goal, focused attention, feedback, discomfort zone. 10,000 hour rule is misinterpretation - quality >> quantity.

**Key mechanic:** Mental representations - experts see patterns novices can't. Build these through struggle with slightly-too-hard problems, not comfortable repetition.

**Ericsson's requirements for adaptive expertise:**

1. **Deliberate practice in controlled environments** (not just experience accumulation)
2. **Deep conceptual understanding** (not just procedural knowledge)
3. **Continued cognitive engagement** (resist premature automation)
4. **Metacognitive monitoring** (self-assessment and adjustment)

### Barbara Oakley
**Core:** Diffuse/focused mode alternation for learning. Chunking - build conceptual units through practice, then combine. Illusion of competence from passive review.

**Key mechanic:** Recall > recognition. Interleaving > blocking. Sleep consolidates. Procrastination is habit, not character - change cue response.

- **Harvard Project Zero brief** - "Developing Adaptive Expertise for Navigating New Terrain" (directly addresses career transitions and organizational contexts)
- **Cambridge Handbook chapter** on engineering design (if you want to understand how adaptive expertise works in complex problem-solving)

---

##### Claude Suggestions:

**For: Slow Feedback + Complex Domains Section**

**What to add & Why:**

1. **The Feedback Problem in Slow/Complex Environments**
   - **Why:** Establishes the core challenge - you can't quickly validate mental models
   - **Source:** `Thought Collection/Todos and Drafts/Raw Source Extracts/Notes from Superforecasters.md` (lines 378-381)
   - **Key insight:** Slow feedback creates two barriers: ambiguous language prevents judging accuracy + time lag allows hindsight bias to distort recall

2. **Strategy: Decompose Big Questions (Fermi-ization)**
   - **Why:** Creates faster feedback loops by breaking complex questions into testable sub-components
   - **Source:** `Notes from Superforecasters.md` (lines 193-206, 528-532)
   - **Application:** Instead of waiting years for outcome, track leading indicators that give incremental feedback
   - **Example from vault:** North Korea crisis question broken into smaller proxies (rocket tests, diplomatic talks, etc.)

3. **Strategy: Outside View + Inside View Synthesis**
   - **Why:** Can't rely on slow personal experience alone - must leverage base rates from similar cases
   - **Source:** `Notes from Superforecasters.md` (lines 209-223)
   - **Key practice:** Start with base rates (outside view) for meaningful anchor, then investigate specifics (inside view) in targeted way, not aimless wandering

4. **Strategy: Dragonfly Perspective (Aggregate Multiple Viewpoints)**
   - **Why:** Since you can't test ideas quickly through action, test them through diverse lenses
   - **Source:** `Notes from Superforecasters.md` (lines 132-146, 225-229)
   - **Practice:** Actively seek contrarian views, reframe problems, ask "Would I be convinced if I were someone else?"
   - **Evidence:** Foxes (who aggregate perspectives) beat hedgehogs in forecasting accuracy

5. **Strategy: Incremental Belief Updating**
   - **Why:** Many small updates (avg 3.5%) avoid both under-reaction and over-reaction to new information
   - **Source:** `Notes from Superforecasters.md` (lines 283-288, 330-337)
   - **Principle:** "Beliefs are hypotheses to be tested, not treasures to be guarded" (line 237)
   - **Connection:** Links to Bayesian thinking (lines 340-352) - update based on diagnostic value of new info

6. **Strategy: Perpetual Beta Mindset**
   - **Why:** In slow-feedback domains, need intrinsic motivation to iterate without external validation
   - **Source:** `Notes from Superforecasters.md` (lines 423-424, 396-398, 420-421)
   - **Evidence:** "Perpetual beta...is roughly three times as powerful a predictor as intelligence" for forecasting success
   - **Components:** Growth mindset + grit when validation is delayed

7. **Caution: Pattern Recognition Can Mislead**
   - **Why:** Complex domains may lack valid cues, leading to false patterns
   - **Source:** `Notes from Superforecasters.md` (lines 69-72)
   - **Key insight:** Intuition works in "a world full of valid cues" - but complex domains may not have them
   - **Implication:** Be wary of System 1 intuition when you haven't had enough feedback loops

8. **Missing: Connect to Transfer of Learning**
   - **Why:** "Bridging" strategy (analogies, pattern extraction) seems especially relevant for complex domains
   - **What's in vault:** The feedback section mentions "hugging" and "bridging" (lines 37-48)
   - **Suggestion:** Bridging helps when you can't practice in realistic conditions (slow feedback) - forces explicit pattern extraction across contexts

**Gaps requiring external resources:**

1. **Deliberate Practice in Slow-Feedback Domains**
   - Ericsson's work (mentioned in feedback section) on how experts create practice when corrective feedback is delayed
   - Look for: Backtesting, simulation, thought experiments as artificial feedback mechanisms

2. **Mental Models for Emergent/Complex Systems**
   - Your `Emergent Systems.md` touches on this, but need more on:
   - Building models when cause-effect is only clear retrospectively
   - First principles reasoning when patterns fail (mentioned in `Complicated and Complex Expertise.md` line 14)

3. **Analogical Reasoning in Complex Problem-Solving**
   - How to effectively use analogies across domains when direct experience is too slow to accumulate

**Supporting material already in vault:**
- `Thought Collection/Books (Single source and note)/Ultralearning - Scott H. Young/Ultralearners 6th principle - feedback.md` - Types of feedback and tactics
- `Thought Collection/Claude Session/Complicated and Complex Expertise.md` - Distinction between domains
- `Thought Collection/Multi-Sourced Notes/Emergent Systems.md` - Nature of complex systems
---

## Summary: Building a Learning Strategy Selector Framework

**Your Goal:** Create a practical framework for building adaptive expertise by matching learning strategies to problem characteristics. This is a _strategy selector_, not a diagnostic tool - it helps answer "Given I know X about my situation, what's the optimal learning approach?"

**Core Framework: 2x2 Matrix**

Two diagnostic dimensions:

1. **Problem Type:** Complicated (stable cause-effect, analyzable, mechanical parts) vs Complex (emergent, adaptive agents, context-dependent)
2. **Feedback Speed:** Fast (rapid iteration possible) vs Slow (outcomes delayed)

These create four quadrants, each requiring different expertise-building strategies:

||**Fast Feedback**|**Slow Feedback**|
|---|---|---|
|**Complicated**|Deliberate practice, drills, pattern libraries|Decompose into fast-feedback sub-problems, document reasoning, import skill from adjacent domains|
|**Complex**|Safe-to-fail probes, rapid iteration, pattern extraction across contexts|Portfolio approach, retrospective coherence, meta-skill development|

**Current Document Structure (What Exists):**

1. ✓ **Curiosity/Knowledge Foundations** - Epistemic curiosity, Matthew Principle, WHY/HOW questions, thinkering
2. ✓ **Tools** - Thinking structures, Second Brain, CODE model
3. ✓ **Matrix visual** - Shows the 2x2 clearly
4. ⚠️ **"Analyze Environment" section** - Exists but prematurely prescribes strategies before establishing both dimensions
5. ⚠️ **"Slow Feedback Techniques"** - Exists but conflates Slow + Complicated with general slow feedback; missing Slow + Complex techniques

**Structural Improvements Needed:**

1. **Rename section:** "Analyze the Environment..." → **"Learning Strategies for Rapid Expertise Building"**
2. **Add bridge section after matrix:** 2-3 paragraphs explaining _why_ each quadrant requires different approaches (the strategic logic before diving into specific techniques)
3. **Reorganize techniques by quadrant:**
    - Fast + Complicated: [techniques]
    - Fast + Complex: [techniques - needs more content]
    - Slow + Complicated: [decomposition, Fermi, prediction documentation]
    - Slow + Complex: [needs more content - portfolio approach, retrospective coherence, safe-to-fail probes]
4. **Content gaps to fill:**
    - Fast + Complex strategies (mentioned "varied context" but needs depth)
    - Slow + Complex strategies (barely touched - this is where Superforecasters material gets confused with your framework)

**Key Insights from Discussion:**

- **Cynefin confusion resolved:** You're not using Cynefin's full model - just the complicated/complex distinction. Chaotic and Clear aren't relevant for a learning strategy selector.
- **Decomposition in complex domains:** Works but with constraint - sub-parts interact non-linearly, so experiments teach you about system dynamics, not just isolated variables
- **Superforecasters material:** Mostly applies to Slow + Complicated (calibrating probabilistic judgment). Slow + Complex requires different approaches (navigation over prediction)
- **Your CAB work example:** Slow + Complex - which is why pure forecasting/analysis has diminishing returns vs safe-to-fail probes that reshape the system

**Next Steps for Development:**

1. Write the bridge section (strategic logic for each quadrant)
2. Synthesize more sources for Fast + Complex techniques
3. Synthesize more sources for Slow + Complex techniques (might need different books than Superforecasters)
4. Decide whether to keep prose flow (Option 1: add bridge + organize by quadrant) vs tighter if-then structure

**Prose Style Preference:** You want free-flowing text rather than bullet points, with clean argument structure but not overly mechanical.
